{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler, OneHotEncoder\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mipywidgets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m interact, FloatSlider, Dropdown\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Step 1: Load and Preprocess Data\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Load the data\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from ipywidgets import interact, FloatSlider, Dropdown\n",
    "\n",
    "# Step 1: Load and Preprocess Data\n",
    "# Load the data\n",
    "df = pd.read_csv(\"C:/Users/masji/OneDrive/Desktop/MLSelfLearn/Capstone/Data/BMR_Dataset.csv\")\n",
    "\n",
    "# Display first few rows and check for missing values\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id     0\n",
      "age        11\n",
      "weight      7\n",
      "height      8\n",
      "gender     10\n",
      "BMR         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id    0\n",
      "age        0\n",
      "weight     0\n",
      "height     0\n",
      "gender     0\n",
      "BMR        0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\masji\\AppData\\Local\\Temp\\ipykernel_14660\\4071247636.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['age'].fillna(df['age'].mean(), inplace=True)\n",
      "C:\\Users\\masji\\AppData\\Local\\Temp\\ipykernel_14660\\4071247636.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['weight'].fillna(df['weight'].mean(), inplace=True)\n",
      "C:\\Users\\masji\\AppData\\Local\\Temp\\ipykernel_14660\\4071247636.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['height'].fillna(df['height'].mean(), inplace=True)\n",
      "C:\\Users\\masji\\AppData\\Local\\Temp\\ipykernel_14660\\4071247636.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['gender'].fillna(df['gender'].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values\n",
    "df['age'].fillna(df['age'].mean(), inplace=True)\n",
    "df['weight'].fillna(df['weight'].mean(), inplace=True)\n",
    "df['height'].fillna(df['height'].mean(), inplace=True)\n",
    "df['gender'].fillna(df['gender'].mode()[0], inplace=True)\n",
    "\n",
    "print(df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id   age     weight      height          BMR  gender_Female  \\\n",
      "0     1243  27.0  73.066833  162.723887  1576.878448            0.0   \n",
      "1     4971  28.0  77.730284  179.495414  1536.656455            1.0   \n",
      "2     1629  57.0  85.704790  158.403052  1697.694955            0.0   \n",
      "3     6201  47.0  67.012186  168.113746  1471.524942            0.0   \n",
      "4     7833  36.0  79.929512  175.561126  1743.147435            0.0   \n",
      "\n",
      "   gender_Male  \n",
      "0          1.0  \n",
      "1          0.0  \n",
      "2          1.0  \n",
      "3          1.0  \n",
      "4          1.0  \n"
     ]
    }
   ],
   "source": [
    "# Encode 'gender' column using OneHotEncoder\n",
    "one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded_gender = one_hot_encoder.fit_transform(df[['gender']])\n",
    "encoded_gender_columns = one_hot_encoder.get_feature_names_out(['gender'])\n",
    "encoded_gender_df = pd.DataFrame(encoded_gender, columns=encoded_gender_columns)\n",
    "\n",
    "# Concatenate encoded gender with original DataFrame and drop original 'gender' column\n",
    "df = pd.concat([df.drop(['gender'], axis=1), encoded_gender_df], axis=1)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\masji\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2199680.2500 - mae: 1469.0524 - val_loss: 1799349.6250 - val_mae: 1327.0934\n",
      "Epoch 2/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1381766.3750 - mae: 1145.9951 - val_loss: 208457.6562 - val_mae: 440.9917\n",
      "Epoch 3/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 95196.0703 - mae: 265.7382 - val_loss: 6544.5493 - val_mae: 64.5706\n",
      "Epoch 4/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6213.9731 - mae: 62.0170 - val_loss: 4339.6270 - val_mae: 51.0149\n",
      "Epoch 5/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4333.9731 - mae: 51.0513 - val_loss: 3758.6396 - val_mae: 47.6310\n",
      "Epoch 6/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3796.7197 - mae: 47.4563 - val_loss: 3495.3008 - val_mae: 46.1974\n",
      "Epoch 7/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3494.9119 - mae: 45.7345 - val_loss: 3320.0542 - val_mae: 45.3550\n",
      "Epoch 8/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3498.3623 - mae: 45.9456 - val_loss: 3169.6404 - val_mae: 44.2492\n",
      "Epoch 9/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3289.7480 - mae: 44.9964 - val_loss: 3048.5439 - val_mae: 43.6180\n",
      "Epoch 10/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3170.1509 - mae: 44.0936 - val_loss: 2957.7024 - val_mae: 43.0262\n",
      "Epoch 11/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3174.0808 - mae: 43.9901 - val_loss: 2903.7139 - val_mae: 42.8467\n",
      "Epoch 12/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2857.1438 - mae: 42.4503 - val_loss: 2845.0942 - val_mae: 42.4741\n",
      "Epoch 13/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2857.3201 - mae: 42.4125 - val_loss: 2798.0671 - val_mae: 42.1690\n",
      "Epoch 14/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2833.2844 - mae: 42.3711 - val_loss: 2762.8743 - val_mae: 41.9059\n",
      "Epoch 15/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2769.7896 - mae: 41.9784 - val_loss: 2739.7676 - val_mae: 41.7311\n",
      "Epoch 16/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2675.7915 - mae: 41.2843 - val_loss: 2725.8486 - val_mae: 41.7016\n",
      "Epoch 17/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2659.2605 - mae: 40.8423 - val_loss: 2700.1565 - val_mae: 41.4686\n",
      "Epoch 18/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2679.6003 - mae: 41.2472 - val_loss: 2701.2502 - val_mae: 41.4164\n",
      "Epoch 19/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2652.5854 - mae: 41.1948 - val_loss: 2685.8406 - val_mae: 41.3872\n",
      "Epoch 20/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2612.7358 - mae: 40.8411 - val_loss: 2674.0056 - val_mae: 41.3196\n",
      "Epoch 21/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2597.5046 - mae: 40.8242 - val_loss: 2681.2085 - val_mae: 41.3956\n",
      "Epoch 22/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2665.4392 - mae: 41.4076 - val_loss: 2678.8184 - val_mae: 41.2637\n",
      "Epoch 23/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2700.3589 - mae: 41.5256 - val_loss: 2694.1125 - val_mae: 41.4061\n",
      "Epoch 24/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2616.6309 - mae: 40.5675 - val_loss: 2693.5920 - val_mae: 41.4067\n",
      "Epoch 25/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2645.0557 - mae: 41.1831 - val_loss: 2660.1135 - val_mae: 41.2198\n",
      "Epoch 26/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2589.1323 - mae: 40.7020 - val_loss: 2688.7676 - val_mae: 41.3151\n",
      "Epoch 27/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2617.6086 - mae: 40.9935 - val_loss: 2684.0862 - val_mae: 41.4953\n",
      "Epoch 28/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2626.2732 - mae: 40.8421 - val_loss: 2658.5239 - val_mae: 41.2740\n",
      "Epoch 29/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2635.3569 - mae: 40.8740 - val_loss: 2662.0608 - val_mae: 41.1924\n",
      "Epoch 30/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2634.4150 - mae: 41.1068 - val_loss: 2764.0891 - val_mae: 41.6899\n",
      "Epoch 31/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2706.4116 - mae: 41.3373 - val_loss: 2697.6953 - val_mae: 41.4230\n",
      "Epoch 32/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2575.8672 - mae: 40.5493 - val_loss: 2660.3086 - val_mae: 41.1891\n",
      "Epoch 33/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2648.4700 - mae: 40.8365 - val_loss: 2666.8369 - val_mae: 41.2367\n",
      "Epoch 34/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2497.9514 - mae: 39.7616 - val_loss: 2658.8965 - val_mae: 41.1761\n",
      "Epoch 35/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2529.7576 - mae: 40.1577 - val_loss: 2697.1934 - val_mae: 41.6708\n",
      "Epoch 36/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2593.8521 - mae: 40.7812 - val_loss: 2661.8398 - val_mae: 41.1138\n",
      "Epoch 37/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2681.6406 - mae: 41.4839 - val_loss: 2678.8472 - val_mae: 41.4586\n",
      "Epoch 38/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2646.0439 - mae: 40.9977 - val_loss: 2679.0505 - val_mae: 41.4515\n",
      "Epoch 39/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2586.4180 - mae: 40.5765 - val_loss: 2685.2900 - val_mae: 41.2891\n",
      "Epoch 40/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2681.5176 - mae: 41.3197 - val_loss: 2660.6780 - val_mae: 41.2705\n",
      "Epoch 41/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2719.4551 - mae: 41.3137 - val_loss: 2660.6873 - val_mae: 41.1631\n",
      "Epoch 42/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2558.0330 - mae: 40.3268 - val_loss: 2672.8206 - val_mae: 41.3735\n",
      "Epoch 43/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2520.3528 - mae: 40.0813 - val_loss: 2690.3186 - val_mae: 41.3685\n",
      "Epoch 44/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2615.5806 - mae: 41.0689 - val_loss: 2673.7744 - val_mae: 41.3890\n",
      "Epoch 45/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2646.4241 - mae: 40.9106 - val_loss: 2681.4622 - val_mae: 41.2681\n",
      "Epoch 46/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2605.7798 - mae: 40.6788 - val_loss: 2659.8274 - val_mae: 41.3067\n",
      "Epoch 47/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2573.7424 - mae: 40.4918 - val_loss: 2668.6479 - val_mae: 41.3850\n",
      "Epoch 48/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2634.5273 - mae: 41.1458 - val_loss: 2679.3857 - val_mae: 41.3703\n",
      "Epoch 49/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2682.9050 - mae: 41.5370 - val_loss: 2674.6230 - val_mae: 41.2863\n",
      "Epoch 50/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2680.0496 - mae: 41.2816 - val_loss: 2660.2173 - val_mae: 41.2174\n",
      "Epoch 51/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2630.9780 - mae: 41.0610 - val_loss: 2644.0737 - val_mae: 41.0366\n",
      "Epoch 52/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2550.4062 - mae: 40.4258 - val_loss: 2644.0911 - val_mae: 41.0755\n",
      "Epoch 53/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2621.2097 - mae: 40.7569 - val_loss: 2725.7761 - val_mae: 41.5762\n",
      "Epoch 54/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2652.5120 - mae: 41.0612 - val_loss: 2672.1511 - val_mae: 41.4100\n",
      "Epoch 55/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2592.4871 - mae: 40.6709 - val_loss: 2662.9316 - val_mae: 41.1445\n",
      "Epoch 56/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2543.3386 - mae: 40.4262 - val_loss: 2693.2715 - val_mae: 41.3083\n",
      "Epoch 57/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2584.9321 - mae: 40.6062 - val_loss: 2650.6157 - val_mae: 41.1885\n",
      "Epoch 58/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2610.7747 - mae: 40.8285 - val_loss: 2648.0754 - val_mae: 41.1187\n",
      "Epoch 59/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2628.5098 - mae: 41.2486 - val_loss: 2670.5771 - val_mae: 41.2418\n",
      "Epoch 60/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2599.5691 - mae: 40.6856 - val_loss: 2656.4241 - val_mae: 41.2169\n",
      "Epoch 61/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2662.0449 - mae: 41.2841 - val_loss: 2667.8906 - val_mae: 41.4244\n",
      "Epoch 62/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2574.9492 - mae: 40.3952 - val_loss: 2668.2578 - val_mae: 41.3393\n",
      "Epoch 63/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2628.3494 - mae: 41.0156 - val_loss: 2647.1689 - val_mae: 41.1079\n",
      "Epoch 64/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2662.0955 - mae: 41.3381 - val_loss: 2670.7495 - val_mae: 41.1956\n",
      "Epoch 65/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2664.2864 - mae: 41.3205 - val_loss: 2641.6033 - val_mae: 41.0328\n",
      "Epoch 66/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2607.8694 - mae: 40.5123 - val_loss: 2642.5728 - val_mae: 41.1014\n",
      "Epoch 67/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2660.7280 - mae: 41.2346 - val_loss: 2658.2351 - val_mae: 41.2654\n",
      "Epoch 68/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2620.3816 - mae: 40.8399 - val_loss: 2705.1580 - val_mae: 41.7399\n",
      "Epoch 69/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2549.7446 - mae: 40.3333 - val_loss: 2675.0859 - val_mae: 41.3997\n",
      "Epoch 70/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2585.7537 - mae: 40.6796 - val_loss: 2646.3796 - val_mae: 41.1225\n",
      "Epoch 71/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2597.2664 - mae: 40.6014 - val_loss: 2668.1768 - val_mae: 41.1993\n",
      "Epoch 72/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2619.0369 - mae: 41.0967 - val_loss: 2719.8020 - val_mae: 41.9241\n",
      "Epoch 73/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2613.4216 - mae: 40.7610 - val_loss: 2678.3884 - val_mae: 41.2784\n",
      "Epoch 74/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2524.9695 - mae: 39.9205 - val_loss: 2683.8928 - val_mae: 41.2925\n",
      "Epoch 75/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2607.7202 - mae: 40.6487 - val_loss: 2713.0034 - val_mae: 41.8041\n",
      "Epoch 76/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2603.8650 - mae: 40.7592 - val_loss: 2666.1536 - val_mae: 41.2329\n",
      "Epoch 77/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2601.4846 - mae: 40.6644 - val_loss: 2644.6814 - val_mae: 41.0534\n",
      "Epoch 78/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2546.4861 - mae: 40.4384 - val_loss: 2660.6660 - val_mae: 41.1022\n",
      "Epoch 79/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2516.0994 - mae: 40.0747 - val_loss: 2658.7656 - val_mae: 41.1537\n",
      "Epoch 80/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2620.9316 - mae: 40.9108 - val_loss: 2656.4438 - val_mae: 41.1485\n",
      "Epoch 81/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2650.9277 - mae: 41.2323 - val_loss: 2644.8789 - val_mae: 41.0212\n",
      "Epoch 82/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2631.8931 - mae: 40.9124 - val_loss: 2640.8428 - val_mae: 41.0664\n",
      "Epoch 83/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2611.9119 - mae: 40.8666 - val_loss: 2662.1086 - val_mae: 41.1618\n",
      "Epoch 84/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2608.8203 - mae: 40.3041 - val_loss: 2737.0015 - val_mae: 41.9659\n",
      "Epoch 85/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2674.2639 - mae: 41.3438 - val_loss: 2656.6653 - val_mae: 41.1690\n",
      "Epoch 86/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2647.5120 - mae: 41.0914 - val_loss: 2666.6597 - val_mae: 41.1334\n",
      "Epoch 87/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2537.5657 - mae: 39.9138 - val_loss: 2644.7004 - val_mae: 41.0563\n",
      "Epoch 88/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2587.2634 - mae: 40.5800 - val_loss: 2694.1887 - val_mae: 41.3775\n",
      "Epoch 89/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2604.8931 - mae: 40.7626 - val_loss: 2657.3052 - val_mae: 41.1655\n",
      "Epoch 90/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2566.8394 - mae: 40.2205 - val_loss: 2638.0894 - val_mae: 41.0433\n",
      "Epoch 91/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2566.3281 - mae: 40.2605 - val_loss: 2645.7048 - val_mae: 41.0550\n",
      "Epoch 92/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2631.6013 - mae: 40.9276 - val_loss: 2668.1089 - val_mae: 41.1725\n",
      "Epoch 93/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2607.5586 - mae: 40.7457 - val_loss: 2644.4724 - val_mae: 41.0953\n",
      "Epoch 94/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2595.9421 - mae: 40.6166 - val_loss: 2693.2549 - val_mae: 41.2991\n",
      "Epoch 95/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2659.9651 - mae: 41.1507 - val_loss: 2640.8555 - val_mae: 41.0494\n",
      "Epoch 96/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2651.5164 - mae: 41.2764 - val_loss: 2651.5464 - val_mae: 41.0532\n",
      "Epoch 97/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2567.6626 - mae: 40.4129 - val_loss: 2675.7400 - val_mae: 41.4339\n",
      "Epoch 98/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2547.0945 - mae: 40.5030 - val_loss: 2640.2261 - val_mae: 41.0852\n",
      "Epoch 99/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2652.7451 - mae: 41.0788 - val_loss: 2648.8782 - val_mae: 41.1650\n",
      "Epoch 100/100\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2578.1604 - mae: 40.4331 - val_loss: 2676.9612 - val_mae: 41.2876\n"
     ]
    }
   ],
   "source": [
    "# Define activity factors for calorie calculations\n",
    "activity_factors = {\n",
    "    \"sedentary\": 1.2,\n",
    "    \"lightly_active\": 1.375,\n",
    "    \"moderately_active\": 1.55,\n",
    "    \"very_active\": 1.725,\n",
    "    \"extra_active\": 1.9\n",
    "}\n",
    "\n",
    "# Step 2: Add calorie requirement columns based on activity levels\n",
    "for activity, factor in activity_factors.items():\n",
    "    df[f'calories_{activity}'] = df['BMR'] * factor\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "numeric_columns = ['age', 'weight', 'height']\n",
    "df[numeric_columns] = scaler.fit_transform(df[numeric_columns])\n",
    "\n",
    "# Step 3: Prepare data for model training\n",
    "X = df[['age', 'weight', 'height', 'gender_Female', 'gender_Male']].values  # Features for training\n",
    "y = df['BMR'].values  # Target variable (BMR)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Define and Compile the Model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='linear')  # Linear activation for regression\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32,\n",
    "                    validation_data=(X_test, y_test), verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Define the Prediction and Calorie Calculation Function\n",
    "def predict_bmr_and_calories(age, weight, height, gender, activity_level):\n",
    "    # Preprocess user input\n",
    "    gender_male = 1 if gender == 'male' else 0\n",
    "    gender_female = 1 if gender == 'female' else 0\n",
    "\n",
    "    # Normalize the input values\n",
    "    normalized_values = scaler.transform([[age, weight, height]])\n",
    "    age_norm, weight_norm, height_norm = normalized_values[0]\n",
    "\n",
    "    # Prepare the input data for prediction\n",
    "    input_data = np.array([[age_norm, weight_norm, height_norm, gender_female, gender_male]])\n",
    "\n",
    "    # Predict BMR using the model\n",
    "    predicted_bmr = model.predict(input_data, verbose=0).item()\n",
    "\n",
    "    # Calculate daily calorie needs based on activity level\n",
    "    calories_needed = predicted_bmr * activity_factors[activity_level]\n",
    "\n",
    "    # Display the results\n",
    "    print(f\"Predicted BMR: {predicted_bmr:.2f}\")\n",
    "    print(f\"Estimated Calories Needed (Activity Level - {activity_level}): {calories_needed:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35027f030cd74568b5dc5fb3a8a8d357",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=30.0, description='Age:', min=7.0, step=1.0), FloatSlider(value=70.0, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.predict_bmr_and_calories(age, weight, height, gender, activity_level)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 6: Create Interactive Widgets\n",
    "# Use interactive widgets to get user input for BMR prediction and calorie calculation\n",
    "interact(\n",
    "    predict_bmr_and_calories,\n",
    "    age=FloatSlider(min=7, max=100, step=1, value=30, description=\"Age:\"),\n",
    "    weight=FloatSlider(min=20, max=200, step=0.5, value=70, description=\"Weight (kg):\"),\n",
    "    height=FloatSlider(min=90, max=250, step=1, value=170, description=\"Height (cm):\"),\n",
    "    gender=Dropdown(options=['male', 'female'], value='male', description=\"Gender:\"),\n",
    "    activity_level=Dropdown(\n",
    "        options=['sedentary', 'lightly_active', 'moderately_active', 'very_active', 'extra_active'],\n",
    "        value='lightly_active', description=\"Activity Level:\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function predict_bmr_and_calories at 0x0000014DF6815EE0>\n"
     ]
    }
   ],
   "source": [
    "def predict_bmr_and_calories(age, weight, height, gender, activity_level):\n",
    "    # Placeholder for your function's code\n",
    "    pass\n",
    "print(predict_bmr_and_calories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FoodCategory             FoodItem per100grams Cals_per100grams  \\\n",
      "0  CannedFruit           Applesauce        100g           62 cal   \n",
      "1  CannedFruit      Canned Apricots        100g           48 cal   \n",
      "2  CannedFruit  Canned Blackberries        100g           92 cal   \n",
      "3  CannedFruit   Canned Blueberries        100g           88 cal   \n",
      "4  CannedFruit      Canned Cherries        100g           54 cal   \n",
      "\n",
      "  KJ_per100grams  \n",
      "0         260 kJ  \n",
      "1         202 kJ  \n",
      "2         386 kJ  \n",
      "3         370 kJ  \n",
      "4         227 kJ  \n"
     ]
    }
   ],
   "source": [
    "dfc= pd.read_csv(\"C:/Users/masji/OneDrive/Desktop/MLSelfLearn/Capstone/Data/calories.csv\")\n",
    "\n",
    "# Display first few rows and check for missing values\n",
    "print(dfc.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FoodCategory        0\n",
      "FoodItem            0\n",
      "per100grams         0\n",
      "Cals_per100grams    0\n",
      "KJ_per100grams      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dfc.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplikasi:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Duplikasi: \", dfc.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplikasi setelah penghapusan:  0\n"
     ]
    }
   ],
   "source": [
    "# Menghapus duplikat\n",
    "dfc = dfc.drop_duplicates()\n",
    "\n",
    "# Mengecek ulang jumlah duplikat\n",
    "print(\"Duplikasi setelah penghapusan: \", dfc.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Apple': 961.54, 'Watermelon': 1666.67, 'Casaba Melon': 1785.71, 'Dragon Fruit': 833.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\masji\\AppData\\Local\\Temp\\ipykernel_14660\\831212957.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selected_foods['Cals_per100grams'] = selected_foods['Cals_per100grams'].str.replace(' cal', '').astype(float)\n"
     ]
    }
   ],
   "source": [
    "# Import library yang diperlukan\n",
    "import pandas as pd\n",
    "\n",
    "# Contoh dataset makanan (pastikan Anda sudah memuat dataset ini sebelumnya)\n",
    "dfc = pd.read_csv(\"C:/Users/masji/OneDrive/Desktop/MLSelfLearn/Capstone/Data/calories.csv\")\n",
    "\n",
    "# Fungsi untuk normalisasi nama makanan\n",
    "def normalize_food_name(food_name):\n",
    "    # Mengonversi huruf pertama dari setiap kata menjadi kapital\n",
    "    return ' '.join([word.capitalize() for word in food_name.split()])\n",
    "\n",
    "# Fungsi utama untuk menghitung porsi makanan berdasarkan input user\n",
    "def calculate_food_portion(food_list, total_calories_needed):\n",
    "    # Validasi jumlah jenis makanan\n",
    "    if len(food_list) > 10:\n",
    "        return \"Error, maksimal 10 jenis makanan\"\n",
    "\n",
    "    # Normalisasi nama makanan sesuai dengan format di dataset\n",
    "    normalized_food_list = [normalize_food_name(food) for food in food_list]\n",
    "\n",
    "    # Filter dataset berdasarkan makanan yang diinput user\n",
    "    selected_foods = dfc[dfc['FoodItem'].isin(normalized_food_list)]\n",
    "\n",
    "    # Jika ada makanan yang tidak ditemukan di dataset, tampilkan pesan error\n",
    "    if selected_foods.empty or len(selected_foods) < len(normalized_food_list):\n",
    "        return \"Beberapa makanan yang diinput tidak ditemukan di dataset.\"\n",
    "\n",
    "    # Konversi kolom 'Cals_per100grams' ke tipe numerik (menghapus satuan \" cal\")\n",
    "    selected_foods['Cals_per100grams'] = selected_foods['Cals_per100grams'].str.replace(' cal', '').astype(float)\n",
    "\n",
    "    # Membagi kalori secara merata ke setiap jenis makanan yang dipilih\n",
    "    calories_per_food = total_calories_needed / len(normalized_food_list)\n",
    "\n",
    "    # Kalkulasi porsi makanan berdasarkan kalori per 100 gram\n",
    "    portions = {}\n",
    "    for index, row in selected_foods.iterrows():\n",
    "        food_name = row['FoodItem']\n",
    "        calories_per_100g = row['Cals_per100grams']\n",
    "        \n",
    "        # Menghitung gram yang dibutuhkan berdasarkan kalori yang diinginkan\n",
    "        grams_needed = (calories_per_food / calories_per_100g) * 100\n",
    "        portions[food_name] = round(grams_needed, 2)  # Membulatkan hingga 2 desimal\n",
    "\n",
    "    return portions\n",
    "\n",
    "# Contoh penggunaan fungsi\n",
    "user_food_list = [\"watermelon\", \"apple\", \"dragon fruit\", \"casaba melon\"]  # Contoh input user\n",
    "total_calories_needed = 2000  # Contoh kebutuhan kalori dari hasil prediksi\n",
    "\n",
    "# Memanggil fungsi dan menampilkan hasil\n",
    "result = calculate_food_portion(user_food_list, total_calories_needed)\n",
    "print(result)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
